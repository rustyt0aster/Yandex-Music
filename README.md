# Обнаружение каверов музыкальных треков. (Хакатона Практикум х Яндекс Музыка)


## Описание проекта

Улучшение качества рекомендаций музыкального сервиса путем точного определения и классификации каверов. 

## Навыки и инструменты

- **python**
- **pandas**
- **matplotlib**
- **seaborn**
- **numpy**
- **langid**
- **lyricsgenius**
- **musicbrainzngs**
- **requests**
- **iso639-lang**
- **iso3166**
- **langid**
- **catboost**
- **spacy**
- **pymorphy3**
- **ipywidgets**
- **simplemma**
- **pywsdp**
- **simplemma**
- **nltk**
- from **pymystem3** import Mystem
- from nltk.stem.wordnet import **WordNetLemmatizer**
- from nltk.corpus import stopwords as **nltk_stopwords**
- from nltk.corpus import **wordnet**
- from nltk.corpus import stopwords

- **scikit-learn**
  - from sklearn.feature_extraction.text import **TfidfVectorizer**
  - from sklearn.model_selection import (
    RandomizedSearchCV,
    train_test_split
)
  - from sklearn.pipeline import Pipeline, make_pipeline

  - from sklearn.linear_model import LogisticRegression
  
  - from sklearn.metrics import (
    recall_score,
    precision_score,
    f1_score,
    precision_recall_curve,
    roc_auc_score,
    roc_curve
)
- **catboost**

## Вывод

Необходимо было построить модель, которая определяет является ли трек оригианлом или кавером.

Для достижения поставленных целей были выполнены следующие Шаги:

- ШАГ 1. (Изучение таблиц)

Были изучены три предоставленных набора данных:

1. covers.json

- Всего в таблице 71597 строк и 3 столбца. 
- Все столбцы соотеветсвуют заявленным типам данным.
- Пропуски присутсвуют в original_track_id
- в track_id все значения уникальны
- В столбце original_track_id(уникальный идентификатор исходного трека) присутсвует большое кол-во пропусков.
- наблюдается несбаласированность классов.

2. lyrics.json

- Всего в таблице 11414 строк и 3 столбца. 
- Все столбцы соотеветсвуют заявленным типам данным.
- Пропуски отсуствуют в таблицах.
- Текст требует предобработки и приведение к необходиому виду для дальнейшего обучения.Стоит учесть, текст представлен на разных языках
- Во всех столбцах присутсвуют дубликаты. В дальнейшем предлагется удалить строки с дубликатами в столбце track_id и удалить столбец lyricId.

Замечено, что данных с информация о тексте трека меньше, чем нам наш датафрем covers.json и meta.json, поэтому необходимо будет выполнить дополнительный поиск данных о треках.


3. meta.json

- Всего в таблице 71769 строк и 7 столбцов. 
- Не все столбцы соотеветсвуют заявленным типам данным.Так из столбца dttm неоходимо будет поулчить информацию о день/месяц/год появлении информации о треке 
- На основании duration предлагается создать новый столбцев также длительности трека, но в минутах. на данной этапе данные даны для миллисикундах и неудобны для для оценки. наблюдаюются аномальные выбросы. необходимо будет их удалить
- Во всех столбцах присутсвует хотя бы один пропуск. Наибольшее кол-во пропусков в столбце language. Далее идет по пропускам isrc. Из-за невозможности восстановить данный идентификатор для трека необходимо удалить строки с пропусками в столбце.
- изучены жанры и выделены те треки, которые не подходят для дальнейшего обучения



- ШАГ 2. (Предобработка данных)

- удалены строки с жанрами, которые не подходят
- столбец dttm. приведен к нужному типу данных
- выполнена фильтрация строк по duration (оставили треки с длительностью от 30 секнуд и до 10 минут)
- Удаление дубликатов в таблице lyrics.json в столбце track_id
- таблицы были объеденены в одну
- Получение дополнительной информации по трекам (парсинг данных по isrc). Выполнено  с использованием Selenium и публичных API (остановились на парсинге метаданных со Spotify API)
- выделен полезные данные из isrc
- выполнено определение языка текста




- ШАГ 3. (Анализ данных)

- Проведен анализ популярности треков по столбцоам. (выделен топ 10 по каждому )
- Замечено, что осовная масса данных сосредоточена за период 2000 - 2023 года. Пик кол-ва регистрации оригиналов приходится на 2022, а каверов за 2021
- В 1993-1997 длительность треков наибольшая. Длительность трека во врмемени разная. Нельзя сказать, что с годами она как-то меняется

- ШАГ 4. (Подготовка к TF-IDF)

- выполнена очистка текста в зависимости от языка. Замечено, что самый популярные язык: Английский, Русский, Испанский
- выполнена лемматизация текстов



- ШАГ 4. (Выделение признаков)

- Целевой признак: track_remake_type
- Признаки: text,	title,	language,	genres,	duration,	artist,	isrc_country_iso,	isrc_organization	isrc_year


- ШАГ 5. (Выделение признаков)

- Целевой признак: track_remake_type
- Признаки: text,	title,	language,	genres,	duration,	artist,	isrc_country_iso,	isrc_organization	isrc_year
- выполнено обучение для TF-IDF


- ШАГ 6. (Обучение моделей)

Рассмотрели 2 модели:

- catboost (на всех признаках)
- Логистическая регрессия ( только на признаке текста)


- Логистическая регрессия
- на оснвонйо выборке: \
Лучшие параметры для модели логистической регрессии с использованием кросс-валидации: {'logisticregression__penalty': 'l2', 'logisticregression__max_iter': 700, 'logisticregression__C': 0.6} \
Наибольшее значение метрики F1 для модели логистической регрессии при лучших гиперпараметрах с использованием кросс-валидации: 0.7422829517396816
- на тестовой: Наибольшее значение метрики F1 на тестовых данных 0.7566988210075027


- catboost 
- на оснвонйо выборке: \
Лучшие параметры для модели CatBoost с использованием кросс-валидации: {'n_estimators': 84, 'max_depth': 5} \
Наименьшее значение метрики RMSE для модели CatBoost при лучших гиперпараметрах с использованием кросс-валидации: 0.8229949025680734 \ 
- на тестовой: Наибольшее значение метрики F1 на тестовых данных 0.8536585365853658 \


Лучше всего себя показала модель catboost 